# Use of the business analysis module

## python end_detect.py

Detects the end of an experiment.  Run it anytime after an experiment has started;
the script will exit when the pipeline finishes processing everything in its queue.

Set up these variables: 
PROMETHEUS_HOST
PROMETHEUS_PASSWORD
PROMETHEUS_ENDPOINT=$PROMETHEUS_HOST"/api/v1/query"
EXPERIMENT_NAMES
EXPERIMENT_JSON

QUERY_WINDOW=90    
DEBOUNCE_PERIOD=30   
POD_DETATCH_ADJUSTMENT=60

It works by querying prometheus every DEBOUNCE_PERIOD seconds, getting
QUERY_WINDOW worth of data, and deciding that the experiment is ended if
there were no packets processed in at least DEBOUNCE_PERIOD seconds.
When it determines the timestamp of the last activity, it waits POD_DETATCH_ADJUSTMENT
seconds after that time, and exits.

You can determine exactly when the experiment ended by either subtracting
POD_DETATCH_ADJUSTMENT from the ending time, or by reading the logs; a line
will read:

EXPERIMENT ENDED AT  2024-04-21T06:34:26.673000+00:00

when the end is detected.

### To test locally
- port forward prometheus to local 9090
- Run an experiment by hand on the cluster
- after the experiment starts running, `kubectl get experiment -A -o json > test4_end_detect/experiments.json`
- edit test4_end_detect/run.sh to change the experiment name and namespace to

## python main.py sim_all

Script that does simulations based on measured data from PlantD data pipelines

Set up the following environment variables:

    - SCENARIO_NAME  (optional - only relevant for scenario-aware simulations)
        - namespace.name of the scenario used for the advanced simulation
    - SCENARIO (optional - only relevant for scenario-aware simulations)
        - json dump of the scenario object to be simulated
    - NETCOSTS_NAME (optional)
        - name of the netcosts CR (namespace.name)
    - NETCOSTS  (optional)
        - json dump of the netcost object to be used
    - DIGITAL_TWIN_TYPE
        - "regular" or "schemaaware"
    - MODEL_TYPE
        - simple, quickscaling, autoscaling
    - TWIN_NAME
        - namespace.name of the model to be constructed from the experiments
    - SIM_NAME
        - A name for the simulation to be run 
    - TRAFFIC_MODEL_NAME
        - The traffic model to use.  See samples directory for an example. 
        - This will be looked up from redis key `plantd:trafficmodel_params:$TRAFFIC_MODEL`
    - REDIS_HOST
    - REDIS_PASSWORD
    - PROMETHEUS_HOST
    - PROMETHEUS_PASSWORD
        - if missing, no password is sent
    - OPENCOST_ENDPOINT
        - Endpoint of the opencost service
    - PIPELINE_LABEL_KEYS
    - PIPELINE_LABEL_VALUES
        - Used by opencost.  Optional.
    - EXPERIMENT_NAMES
        - comma-separated list of namespace.name of each experiment generated by the scenario
    - EXPERIMENT_JSON
        - json dictionary, where the keys are the names of experiments in the form namespace.name, and the values are the records containing describe information for all experiments generated by the secenario 
        - Note that experiments not listed in EXPERIMENT_NAMES will be omitted from analysis (so it's OK to dump every experiment here; they'll just be ignored)
        - can generate with `kubectl get experiments -A -o json`; it's OK to have extras; we just use the EXPERIMENT_NAMES ones
    - LOAD_PATTERN_JSON
        - json dictionary of all load patterns mentioned in the EXPERIMENTS. 
        - Note that load patterns not listed in EXPERIMENTs will be ignored (so it's OK to dump all load patterns here; they'll just be ignored)
        - can generate with `kubectl get loadpatterns -A -o json`; it's OK to have extras; we just use the ones referenced by experiments
    - DATASET_JSON
        - json dictionary of all datasets mentioned in the EXPERIMENTS. 
        - can generate with `kubectl get datasets -A -o json`; it's OK to have extras; we just use the ones referenced by experiments

### To test locally

* First time:
    * Tests are in test1_simple, test3_scenario, and test4_end_detect
    * Set up port forwarding of opencost and thanos. NOT redis (see notes in test/run.sh files)
    * Set up a local redis instance, and make sure run.sh has its port and password
    * edit run.sh in the test directory to turn OFF "FROM_CACHED"
    * use the yaml files in the test directory with kubectl create, to instantiate and run an experiment
    * run test1_simple/run.sh (from the test's parent directory, not from the test directory)
* Subsequently
    * set FROM_CACHED="from_cached" in run.sh
    * run test1_simple/run.sh; this will read from local redis instead of prometheus and opencost

